2013-10-19

Office hours with Aaron from 11 - 1 pm

####Data Curation:

* Could not get Aaron's code to run, realized that we have to install pandas first with sudo get-apt install python-pandas
* Tried to read new data using JSON but could not get the new data into a usable format
* Discussed JSON with Aaron, suggested that we move on to caching the data from his csv file
* However, after looking at the issue tracker and reading more about JSON, group was able to format the new data into a data frame
* Discussed data caching with Aaron to get a better understanding of the goal of the assignment
* Worked with horizontal group members on data caching
* Used to_csv to save the data and wrote code so that the cached data would be named with the date
* Struggled with figuring out how to use git push to save the cached data to our repository
* Read about git commands online and figured out how to use ```git clone```, ```git add```, ```git commit```, and ```git push```

####Visualization:

* 

####Roadblocks:

#####Data Curation:

+ Unfamiliar with JSON representation, and navigating and accessing keys, values, and items in the lists and dictionaries
+ Lack of working knowledge in Python, and understanding how syntax differs from R (i.e. indentation, for loops), as well as how importing libraries and using functions worked
+ How to ```git push``` .ipynb and .py files to the working repository to share code and collaborate with group

Problem solving was a key part to understanding how to work through the data curation stages. JSON was a completely new format that we were unfamiliar with, coupled with learning Python and working in the iPython Notebook (which our group had familiarized ourselves with after the first assignment). We used numerous **strategies** to tackle this assignment:
